{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrithinnnn/survival-in-titanic/blob/main/TitanicSurvival_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeYNs1AGITb-"
      },
      "source": [
        "# Introduction\n",
        "---\n",
        "The goal of this tutorial is to familiarize yourself with basics of data set analysis, feature engineering and model training/ptrdiction. We will look at a simple Titanic survival prediction dataset.\n",
        "\n",
        "# Task description\n",
        "---\n",
        "The task at hand is a simple classification as to whether a passenger on The Titanic survived or not based on the various features available in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmd_gg_0I8uf"
      },
      "source": [
        "# Dataset\n",
        "---\n",
        "We will use the dataset from the Kaggle task [here](https://www.kaggle.com/c/titanic/data?select=train.csv). This is a very basic dataset, used only for illustrative purposes.\n",
        "\n",
        "Lets go ahead and initialize the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZleDjkOqRWyC"
      },
      "source": [
        "## Initialize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgh31bAiJOP2"
      },
      "outputs": [],
      "source": [
        "# Create data directory and download train and test split csv's.\n",
        "%mkdir data\n",
        "%cd data\n",
        "!wget -O train.csv https://drive.google.com/uc?id=1bbUXGCwVKhO0zak-FCkVbAOC6Qwk-UCA&export=download\n",
        "!wget -O test.csv https://drive.google.com/uc?id=1ksmfNosC2Q14MSXfcKj8N_2oOWg3hPVL&export=download\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR4AhKzRPhVI"
      },
      "outputs": [],
      "source": [
        "# All installs here\n",
        "%pip install pandas\n",
        "%pip install seaborn\n",
        "%pip install matplotlib\n",
        "%pip install numpy\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CC-d06RPol1"
      },
      "outputs": [],
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec64SA7rQ1ig"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZnXBSIoPwcR"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"/content/data/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/data/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93vL_8xhQ8q0"
      },
      "source": [
        "### Check meta data and columns available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A23cyDBbRAk9"
      },
      "outputs": [],
      "source": [
        "train_df.info(verbose=True, show_counts=False)\n",
        "print()\n",
        "test_df.info(verbose=True, show_counts=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWbVVkTFRDmO"
      },
      "source": [
        "### Sample data view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP0aCnKoRGHS"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO2drIknRemC"
      },
      "source": [
        "## Exploratory data analysis (EDA)\n",
        "\n",
        "Given any dataset, EDA is the process to systematically analyze the data for any outliers and/or inconsistencies. This is also an opportunity to weed out any unuseful data which otherwise might hinder the learning process or contribute no additional supervision signals to the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwkQDgkCSe7G"
      },
      "source": [
        "### High level statistics\n",
        "As we have loaded our train and test splits into Pandas, we can easily view high level statistics of our data as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmRUqdCJSrtl"
      },
      "source": [
        "#### Numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rOU_4VKR5Oz"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMW1bhSISvwg"
      },
      "source": [
        "#### Categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvJ3eV9HSDxQ"
      },
      "outputs": [],
      "source": [
        "train_df.describe(include=[\"O\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFSu4pksTZb9"
      },
      "source": [
        "### Correlation of categorical features with the target variable\n",
        "Next we visualize the correlation of categorical features available in the dataset with the target variable **`Survived`**. This would give us a clear picture on the most useful features to select from the given set of features.\n",
        "\n",
        "Also the correlation patterns will help us weed out any dependent feature patterns, i.e say if one of the feature is just a linear extrapolation of the other, then the training will be heavily biased and overfit that pattern. So we need to identify such features and isolate them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcEoZYWmXtZt"
      },
      "source": [
        "#### Passenger class vs Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B5YEr4fWnLU"
      },
      "outputs": [],
      "source": [
        "display(\n",
        "    train_df[[\"Pclass\", \"Survived\"]]\n",
        "    .groupby(\"Pclass\", as_index=False)\n",
        "    .mean()\n",
        "    .sort_values(by=\"Survived\", ascending=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6uWsutdbfkh"
      },
      "source": [
        "From the above we can see that passengers travelling in **1**<sup>st</sup> class have had a higher probability of survival than those travelling in **3**<sup>rd</sup> with those in **2**<sup>nd</sup> class having an equal probability of surviving or otherwise.  \n",
        "<br>\n",
        "\n",
        "---\n",
        "> ðŸ’¡ **Note:** This is the probability of survival not the absolute count of people that survived the disaster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIEBmXW5YEsb"
      },
      "source": [
        "#### Sex vs Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFdixuNKYNK_"
      },
      "outputs": [],
      "source": [
        "display(\n",
        "    train_df[[\"Sex\", \"Survived\"]]\n",
        "    .groupby(\"Sex\", as_index=False)\n",
        "    .mean()\n",
        "    .sort_values(by=\"Survived\", ascending=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTJJXi4GcVqo"
      },
      "source": [
        "Female passengers had a higher survival rate. A speculative reason could be that they were the ones evacuated first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVJFqi4PdFVa"
      },
      "source": [
        "#### **Quiz ðŸŽ¯:** Sibling/Spouse count vs Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQDh93DidP2R"
      },
      "outputs": [],
      "source": [
        "# Write a script here to obtain correlation between Sibling/Spouse count and the survival rate.\n",
        "# Based on this correlation arrive at a glaring fact that the data shows you.\n",
        "# column name: SibSp\n",
        "# Write your script here\n",
        "display(\n",
        "    train_df[[\"SibSp\", \"Survived\"]]\n",
        "    .groupby(\"SibSp\", as_index=False)\n",
        "    .mean()\n",
        "    .sort_values(by=\"Survived\", ascending=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKM2S3tp2Pax"
      },
      "source": [
        "Fill the facts inferred from your graph here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYsdJv1ae1HU"
      },
      "source": [
        "### Correlation of numerical features with the target variable\n",
        "Next we move on to the numerical features and analyze its distribution with respect to the target variable i.e the survival rate. This is different from categorical features as its not easy to visualize them as tables. Instead we try and visualize them as plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2t8Dt5ujMIc"
      },
      "source": [
        "#### Passenger class vs Parent/Child count vs Sex vs Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ONXArlFjabQ"
      },
      "outputs": [],
      "source": [
        "g = sns.FacetGrid(train_df, col=\"Survived\")\n",
        "g.map(\n",
        "    sns.pointplot,\n",
        "    \"Pclass\",\n",
        "    \"Parch\",\n",
        "    \"Sex\",\n",
        "    pallete=\"pastel\",\n",
        "    order=[1, 2, 3],\n",
        "    hue_order=[\"male\", \"female\"],\n",
        "    dodge=True,\n",
        ")\n",
        "g.add_legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbZX4Y_N417W"
      },
      "source": [
        "We can infer the below facts from the plots:\n",
        "1. Majority of the **1**<sup>st</sup> class passengers were travelling with their family.\n",
        "2. Most of the **1**<sup>st</sup> class passengers who **survived were travelling alone**.\n",
        "3. The survival rate of people travelling by **2**<sup>nd</sup> class does not have much correlation with the number of people travelling with them.\n",
        "4. Most of the **female** passengers were travelling alone but that does not seem to contribute much for or against their survival rate.\n",
        "\n",
        "\n",
        "> ðŸŽ¯ **Quiz:** These are just some of the interpretations that I could infer from the above graph.  \n",
        "> **Can you try and infer more conclusions ?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMyQgZ3ufPLG"
      },
      "source": [
        "#### Age vs Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3S-IEJ0fOHV"
      },
      "outputs": [],
      "source": [
        "g = sns.FacetGrid(train_df, col=\"Survived\")\n",
        "g.map(plt.hist, \"Age\", bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68k3fsuIEWOt"
      },
      "source": [
        "Below are some of the facts inferred from the graph:\n",
        "\n",
        "1. Infants and children upto **18** years of age seem to have had the highest **survival rate**.\n",
        "2. The **highest number of casualities** were in middle age group of people.\n",
        "3. Compared to middle age people survival rate, the survival rate of elder people have had been higher.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fvcGHC003Zq"
      },
      "source": [
        "#### **Quiz ðŸŽ¯:** Passenger class vs Sibling/Spouse count vs Sex vs Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhSJ725q1WA0"
      },
      "outputs": [],
      "source": [
        "# Write a script to plot a graph between Passenger class, Sibling count and\n",
        "# Sex for each Survival class and infer facts out of it.\n",
        "\n",
        "g = sns.FacetGrid(train_df, col=\"Survived\")\n",
        "g.map(\n",
        "    sns.pointplot,\n",
        "    \"Pclass\",\n",
        "    \"SibSp\",\n",
        "    \"Sex\",\n",
        "    pallete=\"pastel\",\n",
        "    order=[1, 2, 3],\n",
        "    hue_order=[\"male\", \"female\"],\n",
        "    dodge=True,\n",
        ")\n",
        "g.add_legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCFt8GhNVGZ2"
      },
      "source": [
        "Fill the facts inferred from your graph here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEeXMrisPSwd"
      },
      "source": [
        "#### Age vs Travel class vs Sex correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pdT-2tePfwS"
      },
      "outputs": [],
      "source": [
        "g = sns.FacetGrid(train_df, row=\"Pclass\", col=\"Sex\", aspect=1.6)\n",
        "g.map(plt.hist, \"Age\", bins=20)\n",
        "g.add_legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgBHAT4XVDPF"
      },
      "source": [
        "From the above we can see that there is quite some correlation between the age bucket counts vs the combination of travel class and sex.  \n",
        "\n",
        "This is something we will be using down the line to categorize one of the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXMTPb6bFlOH"
      },
      "source": [
        "### Analyzing seemingly unusable features\n",
        "Now we look into the different non-numerical/non-categorical features that are available in the given data. These include the following fields:\n",
        "1. Name\n",
        "2. Cabin\n",
        "3. Ticket\n",
        "4. Fare\n",
        "  \n",
        "\n",
        "Among the above, **cabin and ticket columns logically do not add any specific value** to our task at hand. So we decide to safely drop those fields from our feature space.  \n",
        "\n",
        "\n",
        "With respect to **Fare, we can convert it to a categorical feature** (by defining buckets of fare and identifying them with specific constants) which will be a supplementary signal to the class in which a passenger travels. We will look into in next section.  \n",
        "\n",
        "\n",
        "The Name field also does not add much value but on looking into the values for this field we can see that **most of them have salutations** embedded in it which can act as a supplementary signal to the existing **Sex** field.  \n",
        "\n",
        "\n",
        "We will **extract salutations** from the name fields and then **define a derived categorical feature from their values**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twPUYtAQ2h2i"
      },
      "source": [
        "#### Dropping fields that are really unusable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl-t9dAbyKtk"
      },
      "outputs": [],
      "source": [
        "# Dropping the feature fields that are not required\n",
        "train_df = train_df.drop([\"PassengerId\", \"Ticket\", \"Cabin\"], axis=1)\n",
        "display(train_df.head())\n",
        "print()\n",
        "test_df = test_df.drop([\"PassengerId\", \"Ticket\", \"Cabin\"], axis=1)\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V_JhCSN2ocq"
      },
      "source": [
        "#### Converting **Name** to a valid categorical feature i.e **Title**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THQv763z0F38"
      },
      "outputs": [],
      "source": [
        "train_df[\"Title\"] = train_df.Name.str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
        "test_df[\"Title\"] = test_df.Name.str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
        "display(train_df.head())\n",
        "\n",
        "print(\"\\n\\nDistribution of titles among different people:\")\n",
        "# Check the distribution of titles among different people\n",
        "display(pd.crosstab(train_df[\"Title\"], train_df[\"Sex\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ZvKLM-3D2t"
      },
      "source": [
        "We can clearly see that most of the titles fall into one or two values and the rest can be categorized into a common **Rare** bucket.  \n",
        "\n",
        "Also few titles like **Mlle**, **Miss** etc can be safely replaced with more generic titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58p7pT1R3YeO"
      },
      "outputs": [],
      "source": [
        "# Grouping rare titles and converting few to more common ones\n",
        "for dataset in [train_df, test_df]:\n",
        "    dataset[\"Title\"] = dataset[\"Title\"].replace(\n",
        "        [\n",
        "            \"Capt\",\n",
        "            \"Col\",\n",
        "            \"Countess\",\n",
        "            \"Don\",\n",
        "            \"Dr\",\n",
        "            \"Jonkheer\",\n",
        "            \"Lady\",\n",
        "            \"Major\",\n",
        "            \"Rev\",\n",
        "            \"Sir\",\n",
        "        ],\n",
        "        \"Rare\",\n",
        "    )\n",
        "    dataset[\"Title\"] = dataset[\"Title\"].replace([\"Mlle\", \"Ms\"], \"Miss\")\n",
        "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mme\", \"Mrs\")\n",
        "\n",
        "display(train_df[[\"Title\", \"Survived\"]].groupby([\"Title\"], as_index=False).count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9EvOUel6Ekc"
      },
      "source": [
        "Convert the final **Titles** to integer values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yRK9MN-6JIt"
      },
      "outputs": [],
      "source": [
        "TITLE_MAP = {\n",
        "    title: idx for idx, title in enumerate(train_df[\"Title\"].unique().tolist())\n",
        "}\n",
        "\n",
        "for dataset in [train_df, test_df]:\n",
        "    dataset[\"Title\"] = dataset[\"Title\"].map(TITLE_MAP).fillna(0).astype(int)\n",
        "\n",
        "train_df = train_df.drop(\"Name\", axis=1)\n",
        "test_df = test_df.drop(\"Name\", axis=1)\n",
        "\n",
        "display(train_df.head())\n",
        "print()\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU96iHUwDy7M"
      },
      "source": [
        "#### Convert string categorical features (namely **Sex** and **Embarked**) to integer features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_akBgEV3DopX"
      },
      "outputs": [],
      "source": [
        "SEX_MAP = {\"female\": 1, \"male\": 0}\n",
        "EMBARK_MAP = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "\n",
        "for dataset in [train_df, test_df]:\n",
        "    dataset[\"Sex\"] = dataset[\"Sex\"].map(SEX_MAP).astype(int)\n",
        "\n",
        "    if dataset[\"Embarked\"].hasnans:\n",
        "        \"\"\"\n",
        "        if there are NaN values then fill it with the most recurring\n",
        "        value for Embarked\n",
        "        \"\"\"\n",
        "        dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\n",
        "            train_df[\"Embarked\"].value_counts().idxmax()\n",
        "        )\n",
        "    dataset[\"Embarked\"] = dataset[\"Embarked\"].map(EMBARK_MAP).astype(int)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mBM-0AmMzex"
      },
      "source": [
        "#### Complete continous numeric valued features\n",
        "Some numeric features have NaN values. We need to remove all NaN values and populate with possible best guess values for them.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBLgREqbNZBH"
      },
      "source": [
        "##### **Quiz ðŸŽ¯:** We first need to find the columns with NaN values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEmesfcvNE-T"
      },
      "outputs": [],
      "source": [
        "# Write a short script to print all columns in train and\n",
        "# test data that have atleast one NaN value\n",
        "#for dataset in [train_df, test_df]:\n",
        "dataset.isna().any()[lambda x: x]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLEIIa1LNvMn"
      },
      "source": [
        "##### Handling **NaN**'s in **Age** field\n",
        "From the given feature space, the best guess for the age of a person can be made from the combination of the travelling class and the sex of the person travelling.  \n",
        "\n",
        "This is corroborated from the findings from our EDA above in the section **Age vs Travel class vs Sex correlation**.\n",
        "\n",
        "So we compute the median age for each of the four combinations of travel class and sex and assign it to the NaN's from the same feature values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tPZzQ0INymn"
      },
      "outputs": [],
      "source": [
        "for dataset in [train_df, test_df]:\n",
        "    for i in range(0, 2):\n",
        "        for j in range(0, 3):\n",
        "            age_guess = (\n",
        "                dataset[(dataset[\"Sex\"] == i) & (dataset[\"Pclass\"] == j + 1)][\"Age\"]\n",
        "                .dropna()\n",
        "                .median()\n",
        "            )\n",
        "            dataset.loc[\n",
        "                (dataset[\"Age\"].isnull())\n",
        "                & (dataset[\"Sex\"] == i)\n",
        "                & (dataset[\"Pclass\"] == j + 1),\n",
        "                \"Age\",\n",
        "            ] = (\n",
        "                int(age_guess * 2 + 0.5) * 0.5\n",
        "            )\n",
        "\n",
        "    dataset[\"Age\"] = dataset[\"Age\"].astype(int)\n",
        "\n",
        "display(train_df[\"Age\"].hasnans)\n",
        "display(test_df[\"Age\"].hasnans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZG9eD6SkkSY"
      },
      "source": [
        "##### Handling **NaN**'s in **Fare** field in the test set\n",
        "As there are very less instances of NaN's, we simply take the median value and replace the NaN's with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAWwARtTnCTi"
      },
      "outputs": [],
      "source": [
        "test_df[\"Fare\"].fillna(test_df[\"Fare\"].dropna().median(), inplace=True)\n",
        "display(test_df[\"Fare\"].hasnans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLvIC1aXoj8E"
      },
      "source": [
        "#### Convert continuous numeric features to categories\n",
        "It is always better to bin continous float valued features to specific number of bins. This allows the model to be more robust to any variations in the feature and any anomalies in the absolute value of a feature.  \n",
        "\n",
        "We will use a simple trick where we compute the quartile ranges of the field and assign an integer to each quartile range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdiJDoYIpher"
      },
      "source": [
        "##### Handling the continuous feature **Fare** to categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuPHgfOrpHSR"
      },
      "outputs": [],
      "source": [
        "# We intend to create 4 quartile bands for the continuous\n",
        "# Use a Pandas function to assign the inter quartile range\n",
        "# values of Fare as a new column FareBand\n",
        "\n",
        "train_df[\"FareBand\"] = pd.qcut(train_df[\"Fare\"], 4)\n",
        "train_df[[\"FareBand\", \"Survived\"]].groupby(\n",
        "    [\"FareBand\"], as_index=False\n",
        ").mean().sort_values(by=\"FareBand\", ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXg15gHpr-Wu"
      },
      "outputs": [],
      "source": [
        "def convert_fare_to_band(fare: float):\n",
        "    if fare <= 7.91:\n",
        "        return 0\n",
        "    elif fare > 7.91 and fare <= 14.454:\n",
        "        return 1\n",
        "    elif fare > 14.454 and fare <= 31:\n",
        "        return 2\n",
        "    elif fare > 31:\n",
        "        return 3\n",
        "\n",
        "\n",
        "for dataset in [train_df, test_df]:\n",
        "    dataset[\"Fare\"] = dataset[\"Fare\"].map(convert_fare_to_band)\n",
        "\n",
        "# Drop the temporary column created before\n",
        "train_df = train_df.drop([\"FareBand\"], axis=1)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r6FfWOLxAlW"
      },
      "source": [
        "##### **Quiz ðŸŽ¯:** Handling the **Age** feature to convert it into bands\n",
        "Similar to the **Fare** feature, we need to create inter-quartile ranges and map all the age values that lie within each of the quartile with a specific integer value.  \n",
        "\n",
        "To do this implement the below as per guidance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQPIaDYDxgpe"
      },
      "outputs": [],
      "source": [
        "# Create a temporary feature column \"AgeBand\" in the training\n",
        "# data frame for 5 quartiles.\n",
        "train_df[\"AgeBand\"] = pd.qcut(train_df[\"Age\"], 5)\n",
        "#train_df[\"AgeBand\"] = ???\n",
        "train_df[[\"AgeBand\", \"Survived\"]].groupby([\"AgeBand\"], as_index=False).mean().sort_values(by=\"AgeBand\", ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cfY0liDyNHa"
      },
      "outputs": [],
      "source": [
        "# Create a python function that maps each range of AgeBand to a unique\n",
        "# incrementing class value\n",
        "def convert_age_to_band(age: float):\n",
        "    # dummy value\n",
        "    ret_val: int = -999\n",
        "\n",
        "    if age <= 20:\n",
        "        return 0.0\n",
        "    elif age > 21 and age <= 40:\n",
        "        return 1.0\n",
        "    elif age > 41 and age <= 60:\n",
        "        return 2.0\n",
        "    elif age > 61 and age <= 80:\n",
        "        return 3.0\n",
        "    elif age>81:\n",
        "        return 4.0;\n",
        "\n",
        "    return ret_val\n",
        "\n",
        "\n",
        "for dataset in [train_df, test_df]:\n",
        "    dataset[\"Age\"] = dataset[\"Age\"].map(convert_age_to_band)\n",
        "\n",
        "# Uncomment below line after implementing the previous two cells\n",
        "train_df = train_df.drop([\"AgeBand\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Ph4NlF7hBr"
      },
      "source": [
        "## Final data\n",
        "The final training and test data is displayed below. We have converted the features to their categorical values.  \n",
        "\n",
        "We will now proceed with model training with this training and test split data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK1MfoYg8LFW"
      },
      "outputs": [],
      "source": [
        "display(train_df.head())\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re1W46Rf-IGC"
      },
      "source": [
        "# Model families and Training\n",
        "---\n",
        "\n",
        "We will now create different model families and test our data on them and compare their performance. \n",
        "\n",
        "The task is to train a model with the available training data i.e supervised learning. We explore a combination of regression and classifier models as our problem can be modelled as either a classification or a regression task. \n",
        "\n",
        "To keep things simple we will explore the below models:\n",
        "1. Naive Bayes classifier\n",
        "2. Logistic regression\n",
        "3. Decision trees\n",
        "4. Random Forest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UIc52lTBbO_"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "We now prepare the data into input and output variables in order to be able to give the models its corresponding inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qeEB9vPBjlX"
      },
      "outputs": [],
      "source": [
        "X_train = train_df.drop([\"Survived\"], axis=1)\n",
        "Y_train = train_df[\"Survived\"]\n",
        "\n",
        "X_test = test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USWkXXUx_4cM"
      },
      "source": [
        "## Naive Bayes classifier\n",
        "\n",
        "A Gaussian Naive Bayes classifier are a simple family of probabilistic models that work on the core principle of Baye's theorem.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dyiSLwFAWZS"
      },
      "outputs": [],
      "source": [
        "gaussian_nb = GaussianNB()\n",
        "gaussian_nb.fit(X_train, Y_train)\n",
        "Y_pred = gaussian_nb.predict(X_test)\n",
        "print([Y_pred[idx] for idx in range(0, 5)])\n",
        "\n",
        "acc_gnb = round(gaussian_nb.score(X_train, Y_train) * 100.0, 2)\n",
        "acc_gnb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWhjVmMic7Sp"
      },
      "source": [
        "## Logistic regression\n",
        "Logistic regression models the correlation between categorical input feature variables to that of one or more independent output variables by estimating a logistic function.  \n",
        "\n",
        "This means it tries to fit a generic S-shaped sigmoid curve not necessarily having a mean of 0 and standard deviation of 1. This generic logistic curve tries to capture the inherent function of the independent variables that we are trying to model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qo_QXDheYGj"
      },
      "outputs": [],
      "source": [
        "logistic_reg = LogisticRegression()\n",
        "logistic_reg.fit(X_train, Y_train)\n",
        "Y_pred = logistic_reg.predict(X_test)\n",
        "print([Y_pred[idx] for idx in range(0, 5)])\n",
        "\n",
        "acc_log_reg = round(logistic_reg.score(X_train, Y_train) * 100.0, 2)\n",
        "acc_log_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mUDldLilI7D"
      },
      "source": [
        "## **Quiz ðŸŽ¯:** Decision trees\n",
        "This family of models basically map the problem as a tree where the branches constitute the input features and the output features or classes are part of the leaf node.  \n",
        "\n",
        "They can either be classification trees or regression trees depending on the output values. In this case we will be using a classification tree.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9BoeIuDl24j"
      },
      "outputs": [],
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "\n",
        "# Run predictions on X_test using the model\n",
        "Y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "# Once implemented uncomment all the statements below\n",
        "print([Y_pred[idx] for idx in range(0, 5)])\n",
        "\n",
        "acc_dtree =  round(decision_tree.score(X_train, Y_train) * 100.0, 2)\n",
        "acc_dtree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ePSDzL7kIfi"
      },
      "source": [
        "## Random forest classifier\n",
        "A random forest classifier models the decision using an ensemble of decision trees. The final prediction class is obtained by taking the mode (max frequency) of the classes predicted by all the decision trees.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8B_BA-InOEP"
      },
      "outputs": [],
      "source": [
        "random_fc = RandomForestClassifier(n_estimators=200)\n",
        "random_fc.fit(X_train, Y_train)\n",
        "Y_pred = random_fc.predict(X_test)\n",
        "print([Y_pred[idx] for idx in range(0, 5)])\n",
        "\n",
        "acc_rfc = round(random_fc.score(X_train, Y_train) * 100.0, 2)\n",
        "acc_rfc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQNWJKG9o-PN"
      },
      "source": [
        "## Model performance summary\n",
        "We now come to the end of this EDA and Model exploration and tabulate the performance of each type of model on the training set.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aUO5b7wpMy-"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame(\n",
        "    {\n",
        "        \"Model\": [\n",
        "            \"Naive Bayes\",\n",
        "            \"Logistic Regression\",\n",
        "            \"Random Forest\",\n",
        "            \"Decision Trees\",\n",
        "        ],\n",
        "        \"Accuracy\": [acc_gnb, acc_log_reg, acc_rfc, acc_dtree],\n",
        "    }\n",
        ")\n",
        "models = models.sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
        "display(models)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Kmd_gg_0I8uf",
        "ZleDjkOqRWyC",
        "yO2drIknRemC",
        "m0Ph4NlF7hBr",
        "re1W46Rf-IGC",
        "6UIc52lTBbO_",
        "USWkXXUx_4cM",
        "kWhjVmMic7Sp",
        "_mUDldLilI7D",
        "-ePSDzL7kIfi",
        "LQNWJKG9o-PN"
      ],
      "name": "Copy of TitanicSurvival_SSN_Tutorial",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}